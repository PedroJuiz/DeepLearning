{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PZrN5895QH-X"
   },
   "source": [
    "\n",
    "# Challenge S3: Redes Neuronales Profundas en Keras (DNNs)\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "El objetivo de este challenge es optimizar una DNN capaz de distinguir entre imágenes de prendas de ropa de la base de datos Fasion MNIST.\n",
    "\n",
    "## Punto de partida\n",
    "\n",
    "El punto de partida se corresponde con el código que hemos visto en el worksheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "59FAVqBgQH-Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 5.1477 - accuracy: 0.7651 - val_loss: 0.9135 - val_accuracy: 0.7978\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.6848 - accuracy: 0.8154 - val_loss: 0.6886 - val_accuracy: 0.8190\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.5219 - accuracy: 0.8359 - val_loss: 0.6298 - val_accuracy: 0.8096\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.4471 - accuracy: 0.8503 - val_loss: 0.4833 - val_accuracy: 0.8456\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.4290 - accuracy: 0.8540 - val_loss: 0.5275 - val_accuracy: 0.8368\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.4117 - accuracy: 0.8583 - val_loss: 0.4903 - val_accuracy: 0.8431\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.4078 - accuracy: 0.8592 - val_loss: 0.5625 - val_accuracy: 0.8271\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.3977 - accuracy: 0.8617 - val_loss: 0.4949 - val_accuracy: 0.8458\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3853 - accuracy: 0.8665 - val_loss: 0.4834 - val_accuracy: 0.8444\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3703 - accuracy: 0.8703 - val_loss: 0.5048 - val_accuracy: 0.8318\n",
      "[0.5286984443664551, 0.8241999745368958]\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x  # sólo necesaria si estamos en colab\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Otras librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importamos las capas y modelos que vamos a necesitar para este worksheet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "# Import Fashion MNIST data\n",
    "fashion_mnist = keras.datasets.fashion_mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist\n",
    "\n",
    "# Primeras 10000 imágenes, las utilizamos como validación\n",
    "X_valid = train_images[:10000]\n",
    "Y_valid = train_labels[:10000]\n",
    "\n",
    "X_train = train_images[10000:]\n",
    "Y_train = train_labels[10000:]\n",
    "\n",
    "X_test = test_images\n",
    "Y_test = test_labels\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 28*28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28*28)\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_valid = keras.utils.to_categorical(Y_valid, 10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=128, epochs=10, verbose=1, validation_data=[X_valid, Y_valid])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vc7rmlBQQH-a"
   },
   "source": [
    "## Tareas\n",
    "\n",
    "Vamos a comenzar normalizando los datos de entrada según tres criterios: escalar los valores de entrada al rango 0-1, centrar a una media aproximada de 0 y transformar los datos de entrada aproximadamente a una distribución normal de media 0 y desviación unidad (N(0,1)).\n",
    "\n",
    "A continuación, cambiaremos el criterio de parada del entrenamiento del número máximo de iteraciones (épocas) a terminar el entrenamiento cuando se cumplan unas ciertas condiciones en un subconjunto de los datos u opcionalmente en un conjunto de validación (independiente del entrenamiento).\n",
    "\n",
    "### Normalización 1: escalado de los valores al rango (0, 1)\n",
    "\n",
    "A partir del código anterior, realizar las modificaciones necesarias para que los valores de las imágenes estén escalados al rango (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H5AZ72bbQH-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.5014 - accuracy: 0.8200 - val_loss: 0.4364 - val_accuracy: 0.8414\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3619 - accuracy: 0.8671 - val_loss: 0.3475 - val_accuracy: 0.8700\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3256 - accuracy: 0.8788 - val_loss: 0.3317 - val_accuracy: 0.8800\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2978 - accuracy: 0.8893 - val_loss: 0.3228 - val_accuracy: 0.8789\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.2767 - accuracy: 0.8965 - val_loss: 0.3071 - val_accuracy: 0.8854\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2611 - accuracy: 0.9019 - val_loss: 0.3108 - val_accuracy: 0.8870\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2523 - accuracy: 0.9057 - val_loss: 0.3151 - val_accuracy: 0.8838\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2362 - accuracy: 0.9111 - val_loss: 0.2981 - val_accuracy: 0.8917\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2295 - accuracy: 0.9139 - val_loss: 0.3010 - val_accuracy: 0.8951\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2165 - accuracy: 0.9180 - val_loss: 0.3065 - val_accuracy: 0.8893\n",
      "[0.33695825934410095, 0.880299985408783]\n"
     ]
    }
   ],
   "source": [
    "# Import Fashion MNIST data\n",
    "fashion_mnist = keras.datasets.fashion_mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist\n",
    "\n",
    "# Escalado de imágenes\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Primeras 10000 imágenes, las utilizamos como validación\n",
    "X_valid = train_images[:10000]\n",
    "Y_valid = train_labels[:10000]\n",
    "\n",
    "X_train = train_images[10000:]\n",
    "Y_train = train_labels[10000:]\n",
    "\n",
    "X_test = test_images\n",
    "Y_test = test_labels\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 28*28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28*28)\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_valid = keras.utils.to_categorical(Y_valid, 10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=128, epochs=10, verbose=1, validation_data=[X_valid, Y_valid])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yfAJRUfFQH-b"
   },
   "source": [
    "¿Ha mejorado el resultado? ¿Por qué?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "aXmsuFOuQH-b"
   },
   "source": [
    "Si, el resultado ha mejorado tanto en accuracy como en tasa de pérdida porque la normalización de los valores de los píxeles ayuda al modelo a converger más rápido y a encontrar un mínimo global de la función de pérdida de manera más eficiente.\n",
    "\n",
    "Además, la normalización reduce la varianza entre los píxeles de las imágenes, lo que hace que el modelo sea más robusto y generalizable a nuevas imágenes que no se han utilizado durante el entrenamiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "kNkDDap6QH-b"
   },
   "source": [
    "### Normalización 2: centrar a una media aproximada de 0 \n",
    "\n",
    "AYUDA: Para centrar los valores a una media aproximada de 0, puedes calcular la media total y restarsela a todos los datos. Recuerda que la información de los datos de evaluación (test) no se puede utilizar, pero deben llevar el mismo procesamiento que los datos con los que se entrena la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Sxz6UefJQH-b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 3.6660 - accuracy: 0.7812 - val_loss: 0.7982 - val_accuracy: 0.8244\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.6276 - accuracy: 0.8305 - val_loss: 0.6049 - val_accuracy: 0.8301\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.4840 - accuracy: 0.8468 - val_loss: 0.5324 - val_accuracy: 0.8459\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.4240 - accuracy: 0.8578 - val_loss: 0.5717 - val_accuracy: 0.8375\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3816 - accuracy: 0.8676 - val_loss: 0.4757 - val_accuracy: 0.8572\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3530 - accuracy: 0.8740 - val_loss: 0.4651 - val_accuracy: 0.8573\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3490 - accuracy: 0.8775 - val_loss: 0.4601 - val_accuracy: 0.8592\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.3228 - accuracy: 0.8848 - val_loss: 0.4499 - val_accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3137 - accuracy: 0.8850 - val_loss: 0.4194 - val_accuracy: 0.8736\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3012 - accuracy: 0.8925 - val_loss: 0.4270 - val_accuracy: 0.8723\n",
      "[0.4533665180206299, 0.8647000193595886]\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist\n",
    "\n",
    "# Primeras 10000 imágenes, las utilizamos como validación\n",
    "X_valid = train_images[:10000]\n",
    "Y_valid = train_labels[:10000]\n",
    "\n",
    "X_train = train_images[10000:]\n",
    "Y_train = train_labels[10000:]\n",
    "\n",
    "X_test = test_images\n",
    "Y_test = test_labels\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28*28).astype('float32')\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 28*28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28*28).astype('float32')\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_valid = keras.utils.to_categorical(Y_valid, 10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, 10)\n",
    "\n",
    "# Centramos los datos a una media aproximada de 0\n",
    "train_mean = np.mean(X_train)\n",
    "X_train -= train_mean\n",
    "X_valid -= train_mean\n",
    "X_test -= train_mean\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=128, epochs=10, verbose=1, validation_data=[X_valid, Y_valid])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "syEwYu_fQH-b"
   },
   "source": [
    "### Normalización 3: distribución normal de media 0 y desviación stándard 1 (estandarización N(0,1))\n",
    "\n",
    "AYUDA: Para estandarizar los valores a una distribución aproximadamente normal N(0, 1), puedes calcular la media y la desviación total y aplicar la normalización: x\\_norm = (x - media)/desviacion. \n",
    "\n",
    "Recuerda que la información de los datos de evaluación (test) no se puede utilizar, pero deben llevar el mismo procesamiento que los datos con los que se entrena la red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gCxD6-JaQH-c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.4935 - accuracy: 0.8240 - val_loss: 0.3980 - val_accuracy: 0.8507\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3591 - accuracy: 0.8693 - val_loss: 0.3424 - val_accuracy: 0.8753\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3247 - accuracy: 0.8809 - val_loss: 0.3308 - val_accuracy: 0.8795\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3035 - accuracy: 0.8871 - val_loss: 0.3035 - val_accuracy: 0.8887\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2800 - accuracy: 0.8946 - val_loss: 0.3150 - val_accuracy: 0.8883\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2682 - accuracy: 0.9004 - val_loss: 0.3167 - val_accuracy: 0.8883\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2536 - accuracy: 0.9037 - val_loss: 0.3140 - val_accuracy: 0.8909\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2411 - accuracy: 0.9094 - val_loss: 0.3358 - val_accuracy: 0.8796\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2333 - accuracy: 0.9109 - val_loss: 0.3181 - val_accuracy: 0.8886\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2244 - accuracy: 0.9145 - val_loss: 0.3101 - val_accuracy: 0.8919\n",
      "[0.34741514921188354, 0.880299985408783]\n"
     ]
    }
   ],
   "source": [
    "############## Si al ejecutar el Kernel se bloquea, \n",
    "############## utiliza estas líneas para permitir la \n",
    "############## duplicación de librerías\n",
    "#import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "##############\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist\n",
    "\n",
    "# Primeras 10000 imágenes, las utilizamos como validación\n",
    "X_valid = train_images[:10000]\n",
    "Y_valid = train_labels[:10000]\n",
    "\n",
    "X_train = train_images[10000:]\n",
    "Y_train = train_labels[10000:]\n",
    "\n",
    "X_test = test_images\n",
    "Y_test = test_labels\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28*28).astype('float32')\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 28*28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28*28).astype('float32')\n",
    "\n",
    "# Estandarizamos los datos a una distribución aproximadamente normal N(0, 1)\n",
    "train_std = np.std(X_train)\n",
    "X_train /= train_std\n",
    "X_valid /= train_std\n",
    "X_test /= train_std\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_valid = keras.utils.to_categorical(Y_valid, 10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=128, epochs=10, verbose=1, validation_data=[X_valid, Y_valid])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "p7S281JeQH-c"
   },
   "source": [
    "¿Ha mejorado el resultado con estas normalizaciones? ¿Por qué? ¿Con cuál se obtiene el mejor resultado?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "V7hyWELSQH-c"
   },
   "source": [
    "Si, los resultados de la red neuronal son mejores una vez normalizados los datos. \n",
    "\n",
    "El mejor resultado lo ofrece la primera red, debido a que aún teniendo el mismo accuracy que la red con la tercera normalización, la tasa de pérdida es menor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sLOlywNbQH-c"
   },
   "source": [
    "### Ajuste de la tasa de aprendizaje para optimizar el rendimiento de la red\n",
    "\n",
    "Muchas veces, cuando la función de coste llega a una zona cerca del mínimo, la tasa de aprendizaje es muy grande para acercarse lo más posible a ese mínimo. Por eso, una de las formas de modificar ese valor durante el entrenamiento es llegar a un punto donde no vemos mejora en rendimiento en nuestro conjunto de validación, y empezar a reducir a la mitad el valor de nuestra tasa de aprendizaje. \n",
    "\n",
    "Para ello, podemos utilizar uno de los Callbacks de Keras llamado: ReduceLROnPlateau. Puedes encontrar la información sobre él en el siguiente enlace: https://keras.io/callbacks/#reducelronplateau\n",
    "\n",
    "Es posible que tengas que aumentar las iteraciones máximas para llegar a un caso en el que lleguemos a aplicar este callback, o ver mejor su influencia.\n",
    "\n",
    "Puedes empezar con el código anterior, con una paciencia de 2 iteraciones y una reducción del 50% del valor de la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZOwMX4_kQH-c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0859 - accuracy: 0.9680 - val_loss: 0.3290 - val_accuracy: 0.9078 - lr: 1.2500e-04\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0813 - accuracy: 0.9709 - val_loss: 0.3383 - val_accuracy: 0.9075 - lr: 1.2500e-04\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0782 - accuracy: 0.9719 - val_loss: 0.3433 - val_accuracy: 0.9059 - lr: 1.2500e-04\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0734 - accuracy: 0.9744 - val_loss: 0.3510 - val_accuracy: 0.9057 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0704 - accuracy: 0.9756 - val_loss: 0.3519 - val_accuracy: 0.9059 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0680 - accuracy: 0.9764 - val_loss: 0.3619 - val_accuracy: 0.9067 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0654 - accuracy: 0.9777 - val_loss: 0.3651 - val_accuracy: 0.9068 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0627 - accuracy: 0.9791 - val_loss: 0.3705 - val_accuracy: 0.9061 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0609 - accuracy: 0.9794 - val_loss: 0.3734 - val_accuracy: 0.9070 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0583 - accuracy: 0.9800 - val_loss: 0.3805 - val_accuracy: 0.9068 - lr: 1.0000e-04\n",
      "[0.4360440969467163, 0.9009000062942505]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=128, epochs=10, verbose=1, \n",
    "          validation_data=[X_valid, Y_valid], \n",
    "          callbacks=[reduce_lr])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OZlow9KfQH-c"
   },
   "source": [
    "¿Mejora ahora el resultado?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "z-9ydmevQH-d"
   },
   "source": [
    "El accuracy si mejora, pero si nos fijamos en la tasa de pérdida es un poco más alta."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zzzsCmF4QH-d"
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
